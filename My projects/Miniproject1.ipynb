{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mNJ84Jy3URBf",
        "outputId": "4c73a687-bdf3-4cbb-b766-18f558588158"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.5.2.tar.gz (317.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.3/317.3 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.5.2-py2.py3-none-any.whl size=317812365 sha256=7e787707ee0b2691d030577e6669f823f5f32dd23ea6b4b897d03bd72c4084f9\n",
            "  Stored in directory: /root/.cache/pip/wheels/34/34/bd/03944534c44b677cd5859f248090daa9fb27b3c8f8e5f49574\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.5.2\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qws9ZKQaUXTk",
        "outputId": "7bc00f27-378e-41d5-d14d-2b7ef96bdbc3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('', 177005), ('the', 73641), ('to', 61307), ('of', 52996), ('and', 41009), ('I', 38663), ('in', 33473), ('you', 29527), ('this', 26615), ('a', 25178), ('for', 22669), ('your', 22427), ('my', 21607), ('that', 19074), ('will', 18801), ('as', 17525), ('is', 16418), ('be', 14207), ('with', 13861), ('me', 11971)]\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark import SparkContext\n",
        "\n",
        "\n",
        "spark = SparkSession.builder.appName(\"WordCount\").getOrCreate()\n",
        "sc = spark.sparkContext\n",
        "\n",
        "\n",
        "data = sc.textFile(\"fradulent_emails.txt\")\n",
        "\n",
        "\n",
        "def f(line):\n",
        "    n = line.split(\" \")\n",
        "    return n\n",
        "\n",
        "x = data.flatMap(f)\n",
        "y = x.map(lambda n: (n, 1))\n",
        "\n",
        "WordCount = y.reduceByKey(lambda x, y: x + y)\n",
        "results = WordCount.collect()\n",
        "\n",
        "# print(results)\n",
        "\n",
        "#most frequent 20 words\n",
        "Max20 = sorted(results,key=lambda x: x[1],reverse=True)[:20]\n",
        "print(Max20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hDNNFXr6Vrrw"
      },
      "source": [
        "Question 5: No, Most of the words such as (\"the\",\"to\",\"of\") are common in all forms of communication and they don't indicate fraudulent content.Thus, its hard to tell from those words that the document has fraud emails since the list doesn't contain any suspicious words"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jglZRt2CXXa4"
      },
      "source": [
        "Question 6: Removing common words such as (\"the\",\"to\",\"of\") will be beneficial as those kind of words appear more frequently in each conversation. Also, we can focus on more suspicous words like \"Account\" and \"Password\" to detect in order to spot those suspicous emails.\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SeSEN_WMX_F_"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
